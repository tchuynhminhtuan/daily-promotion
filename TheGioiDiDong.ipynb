{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tchuynhminhtuan/daily-promotion/blob/main/TheGioiDiDong.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TzXjMHJzKGqD"
      },
      "outputs": [],
      "source": [
        "# @title 1. C√†i ƒë·∫∑t m√¥i tr∆∞·ªùng (Ch·∫°y 1 l·∫ßn ƒë·∫ßu)\n",
        "# @markdown B·∫•m n√∫t **Play** (h√¨nh tam gi√°c) b√™n tr√°i ƒë·ªÉ c√†i ƒë·∫∑t.\n",
        "# @markdown *Ch·ªù kho·∫£ng 1-2 ph√∫t cho ƒë·∫øn khi hi·ªán th√¥ng b√°o \"C√†i ƒë·∫∑t ho√†n t·∫•t!\".*\n",
        "\n",
        "!pip install playwright\n",
        "!playwright install chromium\n",
        "!playwright install-deps\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "print(\"‚úÖ C√†i ƒë·∫∑t ho√†n t·∫•t! B·∫°n c√≥ th·ªÉ chuy·ªÉn sang B∆∞·ªõc 2.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true
        },
        "id": "Ve3itvDKKaYk"
      },
      "outputs": [],
      "source": [
        "# @title 2. Nh·∫≠p link v√† Ch·∫°y Tool\n",
        "# @markdown D√°n danh s√°ch link s·∫£n ph·∫©m v√†o √¥ b√™n d∆∞·ªõi (m·ªói link c√°ch nhau b·∫±ng d·∫•u ph·∫©y ho·∫∑c xu·ªëng d√≤ng).\n",
        "# @markdown **N·∫øu ƒë·ªÉ tr·ªëng, tool s·∫Ω ch·∫°y danh s√°ch m·∫∑c ƒë·ªãnh (to√†n b·ªô s·∫£n ph·∫©m Apple).**\n",
        "\n",
        "import asyncio\n",
        "import csv\n",
        "import json\n",
        "import re\n",
        "import os\n",
        "import sys\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "from playwright.async_api import async_playwright, TimeoutError as PlaywrightTimeoutError\n",
        "\n",
        "# --- C·∫•u h√¨nh Input ---\n",
        "ds_link = \"\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "# T√°ch link t·ª´ input form\n",
        "\n",
        "raw_links = ds_link.replace(' ', ',').replace('\\n', ',').split(',')\n",
        "urls_to_process = [link.strip() for link in raw_links if link.strip()]\n",
        "print(f\"üìã ƒêang ch·∫°y danh s√°ch t√πy ch·ªânh ({len(urls_to_process)} link).\")\n",
        "\n",
        "\n",
        "# --- Configuration ---\n",
        "MAX_CONCURRENT_TABS = 4\n",
        "HEADLESS = True\n",
        "USER_AGENT = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
        "\n",
        "# --- Selectors ---\n",
        "SHOCK_PRICE_SELECTORS = [\n",
        "    \".bs_price strong\",\n",
        "    \"//div[@class='bc_title']/div/strong\",\n",
        "    \".oo-left strong\"\n",
        "]\n",
        "\n",
        "SHOCK_PRICE_OLD_SELECTORS = [\n",
        "    \".bs_price em\",\n",
        "    \"//div[@class='bc_title']/div/em\",\n",
        "    \".oo-left em\"\n",
        "]\n",
        "\n",
        "REGULAR_PRICE_SELECTORS = [\n",
        "    \".giamsoc-ol-price\",\n",
        "    \".box-price-present\",\n",
        "    \".center b\",\n",
        "    \"//ul[@class='prods-price']/li//span\"\n",
        "]\n",
        "\n",
        "OLD_PRICE_SELECTORS = [\n",
        "    \".box-price-old\",\n",
        "    \".box-price-present\",\n",
        "    \".center b\",\n",
        "    \"//ul[@class='prods-price']/li//del\"\n",
        "]\n",
        "\n",
        "PRODUCT_NAME_SELECTORS = [\n",
        "    \"h1\",\n",
        "    \"//ul[@class='breadcrumb']/li[last()]\"\n",
        "]\n",
        "\n",
        "PROMO_SELECTORS = [\n",
        "    \"//div[@class='bs_content']/div[@class='block__promo']\",\n",
        "    \".block__promo\",\n",
        "    \".promotions\"\n",
        "]\n",
        "\n",
        "UU_DAI_THEM_SELECTORS = [\n",
        "    \"//div[@class='bs_content']/div[@class='campaign c4 dt']\",\n",
        "    \".campaign.c4.dt\"\n",
        "]\n",
        "\n",
        "STORE_AVAILABILITY_SELECTORS = [\n",
        "    \"//a[@class='store jsSpmarket']\",\n",
        "    \".store.jsSpmarket\"\n",
        "]\n",
        "\n",
        "STORAGE_OPTION_SELECTORS = [\n",
        "    \"a.box03__item.item\"\n",
        "]\n",
        "\n",
        "COLOR_SELECTORS = [\n",
        "    \".box03.color .item.act\",\n",
        "    \".box03.color .item.check\"\n",
        "]\n",
        "\n",
        "# --- Helper Functions ---\n",
        "async def get_text_safe(page, selectors):\n",
        "    \"\"\"Iterates through selectors and returns the text of the first match.\"\"\"\n",
        "    for selector in selectors:\n",
        "        try:\n",
        "            locator = page.locator(selector).first\n",
        "            # Use text_content() to get text even if hidden, as some valid price elements are hidden\n",
        "            text = await locator.text_content(timeout=1000)\n",
        "            if text and text.strip():\n",
        "                return text.strip()\n",
        "        except Exception:\n",
        "            continue\n",
        "    return None\n",
        "\n",
        "async def get_formatted_text_safe(page, selectors):\n",
        "    \"\"\"Iterates through selectors and returns the inner text of the first match, preserving formatting.\"\"\"\n",
        "    for selector in selectors:\n",
        "        try:\n",
        "            locator = page.locator(selector).first\n",
        "            # Use inner_text() to preserve visual formatting (newlines)\n",
        "            text = await locator.inner_text(timeout=1000)\n",
        "            if text and text.strip():\n",
        "                return text.strip()\n",
        "        except Exception:\n",
        "            continue\n",
        "    return None\n",
        "\n",
        "def get_current_date():\n",
        "    tz = pytz.timezone('Asia/Ho_Chi_Minh')\n",
        "    return datetime.now(tz).strftime(\"%Y-%m-%d\")\n",
        "\n",
        "def setup_csv(date_str):\n",
        "    # Output directly to current directory in Colab\n",
        "    file_path = f\"2-mw-{date_str}.csv\"\n",
        "\n",
        "    # Create file with header if it doesn't exist\n",
        "    if not os.path.exists(file_path) or os.stat(file_path).st_size == 0:\n",
        "        with open(file_path, \"w\", newline='', encoding='utf-8') as file:\n",
        "            writer = csv.DictWriter(file, fieldnames=[\n",
        "                \"Product_Name\", \"Color\", \"Ton_Kho\", \"Gia_Niem_Yet\", \"Gia_Khuyen_Mai\",\n",
        "                # \"Chien_Gia\", '+VNPAY', \"Store_Chien\",\n",
        "               \"Date\", \"Khuyen_Mai\", \"Uu_Dai_Them\", \"Link\", 'screenshot_name'\n",
        "            ], delimiter=\";\")\n",
        "            writer.writeheader()\n",
        "    return file_path\n",
        "\n",
        "def write_to_csv(file_path, data):\n",
        "    with open(file_path, \"a\", newline='', encoding='utf-8') as file:\n",
        "        writer = csv.DictWriter(file, fieldnames=[\n",
        "            \"Product_Name\", \"Color\", \"Ton_Kho\", \"Gia_Niem_Yet\", \"Gia_Khuyen_Mai\",\n",
        "            # \"Chien_Gia\", '+VNPAY', \"Store_Chien\",\n",
        "             \"Date\", \"Khuyen_Mai\", \"Uu_Dai_Them\", \"Link\", 'screenshot_name'\n",
        "        ], delimiter=\";\")\n",
        "        writer.writerow(data)\n",
        "\n",
        "# --- Main Logic ---\n",
        "async def process_url(context, url, semaphore, csv_path, date_str):\n",
        "    discovered_urls = []\n",
        "    async with semaphore:\n",
        "        page = await context.new_page()\n",
        "        print(f\"Processing: {url}\")\n",
        "\n",
        "        data = {\n",
        "            \"Product_Name\": \"\", \"Color\": \"\", \"Ton_Kho\": \"0\", \"Gia_Niem_Yet\": \"0\", \"Gia_Khuyen_Mai\": \"0\",\n",
        "            # \"Chien_Gia\": \"\", '+VNPAY': \"\", \"Store_Chien\": \"MW\",\n",
        "             \"Date\": date_str, \"Khuyen_Mai\": \"\", \"Uu_Dai_Them\": \"\", \"Link\": url, 'screenshot_name': \"\"\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            await page.goto(url, timeout=60000)\n",
        "\n",
        "            # Wait for price element to load\n",
        "            try:\n",
        "                # Try to wait for any of the common price selectors\n",
        "                common_selectors = [\".box-price-present\", \".price-present\", \".box-price\", \".giamsoc-ol-price\"]\n",
        "                combined_selector = \", \".join(common_selectors)\n",
        "                # Wait for attached state as elements might be present but hidden\n",
        "                await page.wait_for_selector(combined_selector, timeout=10000, state='attached')\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Price element not found for {url} within timeout. Error: {e}\")\n",
        "\n",
        "            # 0. Discover other storage options\n",
        "            try:\n",
        "                storage_elements = await page.locator(STORAGE_OPTION_SELECTORS[0]).all()\n",
        "                for element in storage_elements:\n",
        "                    href = await element.get_attribute(\"href\")\n",
        "                    if href:\n",
        "                        full_url = \"https://www.thegioididong.com\" + href if href.startswith(\"/\") else href\n",
        "                        discovered_urls.append(full_url)\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Could not extract storage options for {url}: {e}\")\n",
        "\n",
        "            # 1. Product Name\n",
        "            product_name = await get_text_safe(page, PRODUCT_NAME_SELECTORS)\n",
        "            if product_name:\n",
        "                product_name = product_name.strip().replace(\"Mini\", \"mini\")\n",
        "                to_remove = [\"ƒêi·ªán tho·∫°i \", \"M√°y t√≠nh b·∫£ng \", \"Laptop Apple \", \"Tai nghe ch·ª•p tai Bluetooth \", \"Tai nghe Bluetooth \"]\n",
        "                for item in to_remove:\n",
        "                    product_name = product_name.replace(item, \"\")\n",
        "                data[\"Product_Name\"] = product_name\n",
        "            else:\n",
        "                data[\"Product_Name\"] = \"Unknown Product\"\n",
        "\n",
        "            # 2. Price Logic\n",
        "            shock_price = await get_text_safe(page, SHOCK_PRICE_SELECTORS)\n",
        "            if shock_price:\n",
        "                gia_soc = shock_price.replace(\" *\", \"\").replace(\".\", \"\").replace(\"‚Ç´\", \"\").strip()\n",
        "                data[\"Gia_Khuyen_Mai\"] = gia_soc + \"soc\"\n",
        "                old_price = await get_text_safe(page, SHOCK_PRICE_OLD_SELECTORS)\n",
        "                if old_price:\n",
        "                    data[\"Gia_Niem_Yet\"] = old_price.replace(\" *\", \"\").replace(\".\", \"\").replace(\"‚Ç´\", \"\").strip()\n",
        "            else:\n",
        "                reg_price = await get_text_safe(page, REGULAR_PRICE_SELECTORS)\n",
        "                if reg_price:\n",
        "                    data[\"Gia_Khuyen_Mai\"] = reg_price.replace(\"Gi√° d·ª± ki·∫øn: \", \"\").replace(\"Gi√° b√°n:\", \"\").replace(\"*\", \"\").replace(\".\", \"\").replace(\"‚Ç´\", \"\").strip()\n",
        "\n",
        "                old_price = await get_text_safe(page, OLD_PRICE_SELECTORS)\n",
        "                if old_price:\n",
        "                    data[\"Gia_Niem_Yet\"] = old_price.replace(\"Gi√° d·ª± ki·∫øn: \", \"\").replace(\"Gi√° b√°n:\", \"\").replace(\".\", \"\").replace(\"‚Ç´\", \"\").strip()\n",
        "\n",
        "            # 3. Stock Status (Ton_Kho)\n",
        "            # If we found a price, assume in stock (1), unless explicitly out of stock\n",
        "            if data[\"Gia_Khuyen_Mai\"] != \"0\" or data[\"Gia_Niem_Yet\"] != \"0\":\n",
        "                data[\"Ton_Kho\"] = \"Yes\"\n",
        "            else:\n",
        "                data[\"Ton_Kho\"] = \"No\"\n",
        "\n",
        "            # 4. Promotion Info (Khuyen_Mai)\n",
        "            promo_text = await get_formatted_text_safe(page, PROMO_SELECTORS)\n",
        "            if promo_text:\n",
        "                # Clean up the text: remove extra newlines and spaces, preserve meaningful line breaks\n",
        "                lines = [line.strip() for line in promo_text.splitlines() if line.strip()]\n",
        "                cleaned_promo = \"\\n\".join(lines)\n",
        "                data[\"Khuyen_Mai\"] = cleaned_promo\n",
        "\n",
        "            # 5. Additional Offers (Uu_Dai_Them)\n",
        "            uu_dai_text = await get_formatted_text_safe(page, UU_DAI_THEM_SELECTORS)\n",
        "            if uu_dai_text:\n",
        "                # Clean up the text: remove extra newlines and spaces, preserve meaningful line breaks\n",
        "                lines = [line.strip() for line in uu_dai_text.splitlines() if line.strip()]\n",
        "                cleaned_uu_dai = \"\\n\".join(lines)\n",
        "                data[\"Uu_Dai_Them\"] = cleaned_uu_dai\n",
        "\n",
        "            # 6. Color\n",
        "            color_text = await get_text_safe(page, COLOR_SELECTORS)\n",
        "            if color_text:\n",
        "                data[\"Color\"] = color_text\n",
        "\n",
        "            # 6. Screenshot Capture\n",
        "            try:\n",
        "                # Create img_mw directory if it doesn't exist\n",
        "                img_dir = 'img_mw'\n",
        "                if not os.path.exists(img_dir):\n",
        "                    os.makedirs(img_dir)\n",
        "\n",
        "                # Sanitize product name for filename\n",
        "                safe_product_name = re.sub(r'[^\\w\\-\\.]', '_', data['Product_Name']).strip('. ')\n",
        "\n",
        "                # Generate timestamp\n",
        "                tz = pytz.timezone('Asia/Ho_Chi_Minh')\n",
        "                timestamp = datetime.now(tz).strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "\n",
        "                filename = f\"{safe_product_name}_{timestamp}.png\"\n",
        "                full_path = os.path.join(img_dir, filename)\n",
        "\n",
        "                # Set viewport size for better capture (optional, but good for full page details)\n",
        "                await page.set_viewport_size({\"width\": 1920, \"height\": 2080})\n",
        "\n",
        "                # Take screenshot\n",
        "                await page.screenshot(path=full_path, full_page=True)\n",
        "\n",
        "                # Save just the filename to CSV\n",
        "                data['screenshot_name'] = filename\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Could not take screenshot for {url}: {e}\")\n",
        "\n",
        "            print(f\"Done: {data['Product_Name']} - {data['Gia_Khuyen_Mai']}\")\n",
        "            write_to_csv(csv_path, data)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {url}: {e}\")\n",
        "        finally:\n",
        "            await page.close()\n",
        "            return discovered_urls\n",
        "\n",
        "async def main():\n",
        "    date_str = get_current_date()\n",
        "    csv_path = setup_csv(date_str)\n",
        "\n",
        "    # Use the global urls_to_process list\n",
        "    global urls_to_process\n",
        "\n",
        "    print(f\"Found {len(urls_to_process)} initial URLs to process.\")\n",
        "\n",
        "    semaphore = asyncio.Semaphore(MAX_CONCURRENT_TABS)\n",
        "\n",
        "    visited_urls = set()\n",
        "    # Create a local queue from the global list\n",
        "    queue = list(urls_to_process)\n",
        "\n",
        "    async with async_playwright() as p:\n",
        "        browser = await p.chromium.launch(\n",
        "            headless=HEADLESS,\n",
        "            args=[\"--disable-blink-features=AutomationControlled\"]\n",
        "        )\n",
        "        context = await browser.new_context(\n",
        "            user_agent=USER_AGENT,\n",
        "            viewport={\"width\": 1280, \"height\": 720}\n",
        "        )\n",
        "\n",
        "        while queue:\n",
        "            # Process in batches to manage concurrency and dynamic addition\n",
        "            current_batch = []\n",
        "            while queue and len(current_batch) < MAX_CONCURRENT_TABS * 2: # Buffer a bit more than max tabs\n",
        "                url = queue.pop(0)\n",
        "                if url not in visited_urls:\n",
        "                    visited_urls.add(url)\n",
        "                    current_batch.append(url)\n",
        "\n",
        "            if not current_batch:\n",
        "                continue\n",
        "\n",
        "            tasks = [process_url(context, url, semaphore, csv_path, date_str) for url in current_batch]\n",
        "            results = await asyncio.gather(*tasks)\n",
        "\n",
        "            # Add discovered URLs to queue\n",
        "            for discovered_list in results:\n",
        "                for url in discovered_list:\n",
        "                    if url not in visited_urls and url not in queue:\n",
        "                         # Optional: Filter to ensure it's a relevant product link if needed\n",
        "                         queue.append(url)\n",
        "\n",
        "        await browser.close()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"üéâ HO√ÄN TH√ÄNH! üéâ\")\n",
        "    print(f\"üìÇ File k·∫øt qu·∫£: {csv_path}\")\n",
        "    print(f\"üñºÔ∏è Th∆∞ m·ª•c ·∫£nh: img_mw\")\n",
        "    print(\"-\" * 30)\n",
        "    print(\"üëá H∆Ø·ªöNG D·∫™N T·∫¢I FILE:\")\n",
        "    print(\"1. Nh√¨n sang thanh b√™n tr√°i, b·∫•m v√†o bi·ªÉu t∆∞·ª£ng Th∆∞ m·ª•c (üìÅ).\")\n",
        "    print(\"2. T√¨m file .csv v√† th∆∞ m·ª•c img_mw.\")\n",
        "    print(\"3. Chu·ªôt ph·∫£i > Download (T·∫£i xu·ªëng).\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    start_time = datetime.now()\n",
        "    await main()\n",
        "    print(f\"Total execution time: {datetime.now() - start_time}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPz5h0rZLQ4a41/pdFIw1nd",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}