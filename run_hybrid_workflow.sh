#!/bin/bash

echo "ğŸš€ Starting Hybrid Scraper Workflow..."

# 1. Install Dependencies (Just in case)
echo "ğŸ“¦ Checking dependencies..."
pip3 install -r requirements.txt || echo "âš ï¸ Warning: Pip install failed. Assuming packages are present or handled by another python."
python3 -m playwright install chromium

echo "3. Run Local Scrapers (FPT & MW Only - Parallel)..."
# echo "ğŸ•·ï¸ Running FPT & MW Scrapers..."
# python3 code/1-Apple_FPT_playwright.py &
# python3 code/2-Apple_MW_playwright.py &
# wait
# echo "âœ… FPT & MW Scrapers Completed."

# 4. Generate Final Report
# echo "ğŸ“Š Generating Final Report..."
# python3 code/generate_report.py

echo "âœ… Hybrid Workflow Complete!"

# 5. Push Results (Data + Code Updates) to GitHub
echo "ğŸš€ Pushing results to GitHub..."

# 5.1 Add Code & Config (Ensure GitHub Action has latest logic)
git add code/
git add .github/


# 5.2 Add Daily Data (Specific files only)
DATE=$(date +%Y-%m-%d)
git add "content/$DATE/1-fpt-$DATE.csv" || echo "âš ï¸ FPT CSV not found?"
git add "content/$DATE/2-mw-$DATE.csv" || echo "âš ï¸ MW CSV not found?"

git commit -m "Auto: Update Daily Promotion Data (FPT/MW Local Run) - $(date)" || echo "âš ï¸ No changes to commit"
git stash
git pull origin main --rebase
git stash pop || echo "âš ï¸ Auto-merge conflict or nothing to pop. Continuing..."
git push

echo "ğŸ‰ Done! Data synced to GitHub."
