name: Daily Scraping Job

on:
  schedule:
    # Runs at 02:00 UTC (09:00 PM Vietnam Time) every day
    - cron: "0 2 * * *"
  workflow_dispatch: # Allows manual trigger from GitHub UI

permissions:
  contents: write

jobs:
  scrape_and_report:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          python -m playwright install chromium
          python -m playwright install-deps

      - name: Run Scrapers
        env:
          MAX_CONCURRENT_TABS: 10
          TAKE_SCREENSHOT: "False"
          BLOCK_IMAGES: "True"
          PROXY_SERVER: ${{ secrets.PROXY_SERVER }}
          # Proxy Toggles (True/False)
          ENABLE_PROXY_FPT: "False"
          ENABLE_PROXY_MW: "False"
          ENABLE_PROXY_VIETTEL: "False"
          ENABLE_PROXY_HOANGHA: "False"
          ENABLE_PROXY_DDV: "False"
          ENABLE_PROXY_CPS: "False"
          # Test Mode (True/False) - Limits to 4 URLs
          TEST_MODE: "False"
        run: |
          echo "Starting Daily Promotion Scraping..."

          echo "3. Scraping Viettel Store..."
          python3 code/3-Apple_Viettel_playwright.py

          echo "4. Scraping Hoang Ha Mobile..."
          python3 code/4-Apple_HoangHa_playwright.py

          echo "5. Scraping Di Dong Viet..."
          python3 code/5-Apple_DDV_playwright.py

          echo "6. Scraping CellphoneS..."
          python3 code/6-Apple_CPS_playwright.py

          echo "All scrapers completed."

      - name: Generate Report
        run: |
          echo "Generating HTML Report..."
          # Run the interactive report in non-interactive mode (default)
          python3 code/generate_report.py

      - name: Commit and Push Results
        run: |
          git config --global user.name "GitHub Action Scraper"
          git config --global user.email "action@github.com"

          # Add new content files (data)
          git add content/

          # Add the updated report
          git add docs/index.html

          # Commit if there are changes
          git commit -m "Auto: Update Daily Promotion Data & Report [skip ci]" || echo "No changes to commit"

          # Pull latest changes to avoid conflicts (Fix for concurrent runs/edits)
          git pull --rebase origin main

          # Push changes
          git push
